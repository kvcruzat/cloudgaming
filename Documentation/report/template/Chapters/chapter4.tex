\chapter{Implementation}
\label{chapter4}

\section{Game Implementation}
This section will outline how the game designs in section 3.2 in the design chapter were implemented and their justification. The programming language used was C++ because it is known for its wide usage in commercial games. One of the main advantages of using C++ is that is a low level language which gives more performance and performance is an important factor in games. 
\newline
\par
Another reason that C++ is used is that it supports many libraries and one of the libraries that is supported is OpenGL. OpenGL stands for Open Graphics Library and is used to render 3D graphics and supports multiple platfroms (Windows, Linux, OSX) \cite{opengl}. Since OpenGL only deals with 3D rendering, Qt is used as a framework to help build the game. Qt is a framework that is used to develop applications which also supports multiple platforms like OpenGL \cite{qt}. Qt has an OpenGL module to make developing in OpenGL easier and can takes advantage of the whole Qt API for non-OpenGL specifc functionality such as networking which will be explained in section 4.2.
\newline
\par
As shown in Figure \ref{fig:game}, a procedurally generated tree is being modelled along with lighting and shadows. The interface controls on the side are used for testing such as moving the tree to test the shadow and increasing the complexity of the tree. Frames per second counter is implemented and is outputted in the terminal as shown in \ref{fig:gamefps}. The flight simulator can be controlled using the following keyboard commands:
\begin{itemize}
 \item W / S		-	Accelerate / Decelerate
 \item Q / E 		-	Roll Left / Roll Right
 \item Up / Down 	-	Pitch Down / Pitch Up
 \item Left / Right	-	Yaw Left / Yaw Right
 \item Space		-	Stop Movement
 \item F 			-	Toggle FPS counter
\end{itemize}

\begin{figure}[h!]
 \centering
 \includegraphics[width=\linewidth]{images/game.png}
 \caption{Screenshot of game with a procedurally generated tree}
 \label{fig:game}
\end{figure}

\begin{figure}[h!]
 \centering
 \includegraphics[width=0.5\linewidth]{images/gamefps.png}
 \caption{Screenshot of frames per second beind display in the terminal}
 \label{fig:gamefps}
\end{figure}

\section{Cloud Gaming}
The basic cloud gaming system implementation uses Qt's framework for the networking in terms of client and server connection. Since Qt was already used for OpenGL, using Qt for networking will make communication easier. The client program is simply a Qt program that connects to the server program through IP address and port number using Qt's networking module. Once a connection is made, a Qt window appears that will listen to keyboard commands from the user. Only commands that is mapped for the flight simulator controls is accepted as well as held keys being taken in to account then these commands are sent to the server. The server accepts these inputs and simulates the game commands so the game engine can process them to produce the next frames as shown in Figure \ref{fig:gamecommands}.

\begin{figure}[h!]
 \centering
 \includegraphics[width=0.7\linewidth]{images/gamecommands.png}
 \caption{Screenshot of client connection to server and sent commands}
 \label{fig:gamecommands}
\end{figure}

Due to time constraints and setbacks, the video streaming portion of the cloud gaming system was not completed so the initial implementation plans are outlined. The rendered frames on the server side needed to be rendered off screen so it will not display on the server machine. This is done by using Qt's QOffscreenSurface class that allows rendering with OpenGL on an arbitrary thread without the need to create a QWindow then these offscreen rendered frames are then captured in to QImage format \cite{qoffscreen}. Capturing frames to QImage format was actually already implemented but further work on it was not carried out.
\newline
\par
The captured QImage frames are then to be encoded in to streamable H.264 MP4 video format since it is compressed so video traffic data size is smaller. This was supposed to be done using a Qt wrapper called QtFFmpegWrapper\cite{qtffmpeg} for FFmpeg which helps encode and decode video. It uses Qt QImage to exchange video frames with the encoder/decoder. Unfortunately, this code has not been updated for three years so some functions have been deprecated with recent Qt and FFmpeg versions leading to it not being able to be compiled. With the time constraints, learning the ffmpeg library to manually encode QImage data would have been too time consuming with the networking implementations and report deliverables still to be completed.
\newline
\par
The next step would have been to stream the video frames to the client using live555 library. The live555 media server is a complete RTSP (Real Time Streaming Protocol) server application \cite{live555}. The thin client program can then receive and play these video frames back to the window using Qt's media player RTSP compliant capabilities so the user can see the response of their keyboard commands.
 
\section{Networking Implementation}
The original networking implementation idea was to use the University of Leeds' School of Computing cloud testbed for testing software-defined networking in a real data centre network. Open vSwitch is an example of a virtual switch which is a software program that enables communications between virtual machines \cite{openvswitch} which makes it essential to SDN deployments in data centres. Even though the cloud testbed is capable of using Open vSwitch, it was not enabled when it was first set up which is the only time it can be enabled. The other option is to use a virtual network to simulate a network and its latencies as well as the video traffic.

\subsection{Mininet Virtual Network}
Mininet is a tool that can be used to create a virtual network on a single machine with the ability to use virtual switches such as Open vSwitch. Latencies and bandwidth limits can be set on the links between the switches to simulate real world link delays and limitations. The bandwidth limitations that is set on the links between the player hosts and the core switch of the data centre is based on the UK's average network bandwidth in different areas \cite{avgbandwidth} as shown in Table \ref{table:links}. The link delay from the players to the core switch is set to 15ms for all players since 30ms is an average ping time to a typical data centre location. The link delays in the data centre are all set to 1ms since there should be little to no latency where server machines are close to each other. Figure \ref{fig:mnnetwork} shows a diagram of the mininet virtual network along with the IP address of the hosts and port numbers of switch links as well as host and switch names for easier referencing.

\begin{table}[h!]
\centering
\begin{tabular}{|l|l|l|}
\hline
\multicolumn{1}{|c|}{\textbf{Connection}} & \multicolumn{1}{c|}{\textbf{Bandwidth}} & \multicolumn{1}{c|}{\textbf{Link Delay}} \\ \hline
\textbf{h1 -\textgreater s1}             & 70 Mbps                                 & 15 ms                                    \\ \hline
\textbf{h2 -\textgreater s1}              & 50 Mbps                                 & 15 ms                                    \\ \hline
\textbf{h3 -\textgreater s1}              & 30 Mbps                                 & 15 ms                                    \\ \hline
\end{tabular}
\caption{Table showing player host link parameters}
\label{table:links}
\end{table}

\begin{figure}[h!]
 \centering
 \includegraphics[width=\linewidth]{images/mnnetwork.png}
 \caption{Mininet network topology with port numbers and host names and IP address}
 \label{fig:mnnetwork}
\end{figure}

\subsection{OpenDaylight SDN Controller}
Several SDN controllers were explored such as NOX which is the first SDN controller initially developed with OpenFlow by Nicira Networks then was made open source. Other open source controllers include POX and Beacon which is one of the most popular \cite{sdncontroller}. Beacon is a Java-based OpenFlow Controller and which many current commercial controllers are based on such as Floodlight. The SDN controller that was used for this is OpenDaylight which is the controller companies such as HP, Cisco and IBM used after using controllers based off Beacon.
\newline
\par
OpenDaylight was released in 2014 with its first code release names "Hydrogen". The version that is used in this project is OpenDaylight's fifth release which as of this project it is OpenDaylight's current version. OpenDaylight provides an easy to use command line interface and web graphical user interface for flow statistics, also it uses OpenFlow as its SDN protocol.
\newline
\par
Mininet can connect to this controller so the virtual network can be managed by OpenDaylight. Using the pingall command in Mininet's CLI (Command Line Interface) will have every host ping all other hosts so they can discover each other. The network topology can then be easily viewed in OpenDaylight's web GUI as shown in Figure \ref{fig:odltopo}. The host machines are shown using black boxes and switches are shown using blue boxes.

\begin{figure}[h!]
 \centering
 \includegraphics[width=\linewidth]{images/odltopo.png}
 \caption{OpenDaylight network topology}
 \label{fig:odltopo}
\end{figure}

\subsection{Load Balancer}
To communicate with the OpenDaylight controller, its northbound API was used through REST API calls. Initially, Postman which is a Google Chrome extension tool to make API calls was used to test out retrieval of flow statistics and to push flows. The load balancer application was created in python since it can be used to easily create simple programs since it will mainly be making REST API calls. The load balancer code was based on code at \url{https://github.com/nayanseth/sdn-loadbalancing} and YANG UI in the OpenDaylight web GUI. The YANG UI helps in development of applications by listing and executing APIS for the SDN controller.
\newline
\par
The load balancer application asks for user input for two machines, the source host machine and destination host machine. An API call is made to retrieve the network topology which includes the host names and switches and the links. The python package NetworkX is used to store the retrieved network. NetworkX also include a built in Dijkstra's algorithm function and is used to compute all the shortest paths between the two specified hosts. A weight of 1 is used for each link so the paths with the shortest amount links in them are found. Multiple paths are found so the cost for each patch are calculated to find the chosen path to be used for that flow.
\newline
\par
For each switch of each shortest path, multiple REST calls are made so packet statistics can be obtained. The amount of packets received and transmitted are summed up and then subtracted from the amount of packets received and transmitted two seconds later. This gives the transmission rate for that switch which is essentially the amount packets going through that switch in the span of two seconds. The transmission rate is accumulated for every switch in a path and the final value is the cost of that path or in other words the amount of load in that path.. The path with the minimum cost is then chosen to be the flow route between the two host machines. This flow is then pushed to the SDN controller with REST calls and two of them are made for one for each direction of the flow.
\newline
\par
The original code was improved on by allowing for multiple instances of load balancing as the original could only work for a single flow. If multiple flows were attempted to be pushed it would overwrite previously pushed flows only allowing for one flow to be load balanced. This means load balancing in the virtual network created for this project will not work as multiple traffic flows will be using the network simultaeneously. The improved version allows this so multiple flows can be pushed to their lowest cost path for evenly spread traffic so therefore reducing congestion. These flows are deleted by a python script that loops through every switch and deletes every possible flow that could have been installed through REST API calls.
\newline
\par
Load balancing was tested by using a network packet analyser tool called Wireshark \cite{wireshark}. Once load balancing is executed, Wireshark was used on a switch and port number that is a part of the lowest load path then filter all packets that is from an IP address or going to an IP address of a host machine that is part of the load balanced path. UDP packets were being displayed in Wireshark which means that the traffic was using the load balanced path. To further confirm this, Wireshark was used on a switch that is part of a path that is not the pushed flow. Due to the design of the network, there can only be two shortest paths from a player host to a server host. This means Wireshark should not pick up any UDP packets as it should be using the path set by the application which was the case so load balancing is working.
\newline
\par
The following figures shows the working load balancer application using the network topology shown in \ref{fig:mnnetwork}. The simulated traffic is from h4 to h1 host machines and another traffic going from h5 to h2. The two possible paths for both traffic flows is through the switches s4::s2::s1 annd s4::s4::s1.
\newline
\begin{figure}[h!]
 \centering
 \includegraphics[width=\linewidth]{images/loadbalancing/h1toh4.png}
 \caption{Screenshot of load balancer for h4 to h1 traffic. Path s4::s2::s1 was chosen as least load path so this path was pushed to the SDN controller.}
 \label{fig:h1toh4}
\end{figure}

\begin{figure}[h!]
 \centering
 \includegraphics[width=\linewidth]{images/loadbalancing/h2toh5.png}
 \caption{Screenshot of load balancer for h5 to h2 traffic. Path s4::s3::s1 was chosen as least load path.}
 \label{fig:h2toh5}
\end{figure}

\begin{figure}[h!]
 \centering
 \includegraphics[width=\linewidth]{images/loadbalancing/balancedcosts.png}
 \caption{Screenshot showing load balanced paths with almost equal computed costs for each path of 76660 and 7518 packets}
 \label{fig:balancedcosts}
\end{figure}

\begin{figure}[h!]
 \centering
 \includegraphics[width=\linewidth]{images/loadbalancing/flows.png}
 \caption{Postman request showing pushed flows in switch s1}
 \label{fig:flows}
\end{figure}

\begin{figure}[h!]
 \centering
 \includegraphics[width=\linewidth]{images/loadbalancing/s2fromh1.png}
 \caption{Wireshark showing UDP packets for h4 to h1 traffic going through switch s2 port 2.}
 \label{fig:s2fromh1}
\end{figure}

\begin{figure}[h!]
 \centering
 \includegraphics[width=\linewidth]{images/loadbalancing/s2fromh2.png}
 \caption{Wireshark showing no packets are going through switch s2 port 2 for h5 to h2 traffic}
 \label{fig:s2fromh2}
\end{figure}

\begin{figure}[h!]
 \centering
 \includegraphics[width=\linewidth]{images/loadbalancing/s3fromh2.png}
 \caption{Wireshark showing UDP packets going through switch s3 port 2 for h5 to h2 taffic}
 \label{fig:s3fromh2}
\end{figure}

\begin{figure}[h!]
 \centering
 \includegraphics[width=\linewidth]{images/loadbalancing/s3fromh1.png}
 \caption{Wireshark showing no packetws going through switch s3 port 2 for h4 to h1 traffic}
 \label{fig:s3fromh1}
\end{figure}